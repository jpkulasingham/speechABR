{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed7c0a55-ad45-4721-a2e2-dc44ae626cdc",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1414cf-a62a-40de-ba3a-909364401fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import eelbrain as eel\n",
    "import numpy as np\n",
    "import scipy, pathlib, importlib, mne, time, os, sys\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import preprocessing as pre\n",
    "import models as md\n",
    "import plotting\n",
    "from pathnames import *\n",
    "importlib.reload(pre)\n",
    "importlib.reload(md)\n",
    "importlib.reload(plotting)\n",
    "\n",
    "mne.set_log_level(verbose='error')\n",
    "\n",
    "verbose = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d628f12-6ddb-4825-9d26-c072978e053f",
   "metadata": {},
   "source": [
    "# Load EEG data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199619d0-f1c4-43f2-ad13-8698ff5cec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = 'Cz'\n",
    "refs = ['EXG1', 'EXG2'] # mastoids\n",
    "\n",
    "out_path_data.mkdir(exist_ok=True, parents=True)\n",
    "rewrite_output = False\n",
    "subjects = [f'part_{i:03d}' for i in range(1, 26)]\n",
    "\n",
    "for stimtype in ['in', 's']: # 'in': inserts, 's': speakers\n",
    "    speechfiles = [f'{stimtype}_speech_{i}a' for i in range(1,5)] + [f'{stimtype}_speech_{i}b' for i in range(1,5)]\n",
    "    clickfile = f'{stimtype}_clicks_4c'\n",
    "\n",
    "    print(speechfiles)\n",
    "\n",
    "    # loop over subjects\n",
    "    for subject in tqdm(subjects):\n",
    "        filename = preprocessed_path / f'{subject}_{stimtype}_speech_{ch}_reref_ergs.pkl'\n",
    "        if filename.exists() and not rewrite_output:\n",
    "            print('skipping', subject, filename)\n",
    "            continue\n",
    "\n",
    "        subject_folder = rawdata_path / subject\n",
    "\n",
    "        # speech files\n",
    "        eegs = [] # eeg\n",
    "        ergs = [] # Erg\n",
    "        eegfs = [] # eeg file names\n",
    "        fp_ergs = [] # first peak time in Erg channel (eeg and Erg start after this)\n",
    "        for eegf in speechfiles:\n",
    "            if subject == 'part_018' and eegf == 'in_speech_4b': # part_018 has missing data error in trial 4b\n",
    "                continue\n",
    "            if subject == 'part_024' and eegf in ['in_speech_2a', 'in_speech_4b']: # part_024 has flat ERG channels for trials 2a and 4b\n",
    "                continue\n",
    "            eegfile = subject_folder / f'P{subject[-3:]}C{eegf}.bdf'\n",
    "            if not eegfile.exists():\n",
    "                print(f'FILE {eegfile.stem} NOT FOUND')\n",
    "                continue\n",
    "            # load EEG, reref and extract channels\n",
    "            eeg_a, erg_a, erg_start = pre.load_eeg(eegfile, ch=ch, refs=refs)\n",
    "            eegs.append(eeg_a)\n",
    "            eegfs.append(eegfile.stem)\n",
    "            ergs.append(erg_a)\n",
    "            fp_ergs.append(erg_start)\n",
    "        eel.save.pickle(dict(eegs=eegs, filenames=eegfs, fp_ergs=fp_ergs, ergs=ergs), preprocessed_path / f'{subject}_{stimtype}_speech_{ch}_reref_ergs.pkl')\n",
    "\n",
    "        # click file\n",
    "        eegfile = data_path / subject / f'P{subject[-3:]}C{stimtype}_clicks_4c.bdf'\n",
    "        eeg_a, erg_a, erg_start = pre.load_eeg(eegfile, ch=ch, refs=refs) # preprocessing\n",
    "        eel.save.pickle(dict(eeg=eeg_a, erg=erg_a, erg_start=erg_start), preprocessed_path / f'{subject}_{stimtype}_clicks_{ch}_reref_{\"\".join(refs)}.pkl')\n",
    "\n",
    "        # also load io clicks\n",
    "        if stimtype=='in': \n",
    "            eegfile = data_path / subject / f'P{subject[-3:]}Cio_clicks_4c.bdf'\n",
    "            eeg_a, erg_a, erg_start = pre.load_eeg(eegfile)\n",
    "            eel.save.pickle(dict(eeg=eeg_a, erg=erg_a, erg_start=erg_start), preprocessed_path / f'{subject}_io_clicks_{ch}_reref_{\"\".join(refs)}.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0982ec68-203a-40d6-a125-69b387d6dd38",
   "metadata": {},
   "source": [
    "# Click ERP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef8e59c-7745-4992-8d7d-eac85db86410",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(md)\n",
    "importlib.reload(pre)\n",
    "\n",
    "filttype = 'FIR'\n",
    "lowc = 30 # lower cutoff frequency \n",
    "highc = 500 # higher cutoff frequency\n",
    "ch = 'Cz'\n",
    "refs = ['EXG1', 'EXG2'] # mastoids\n",
    "rewrite_output = False # If False, skip participants that have already been analyzed. If True, analyze all participants and overwrite results \n",
    "\n",
    "clicks_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "verbose = True # debug print outs\n",
    "twin = (-0.02, 0.04) # time window for erps/trfs\n",
    "subjects = [f'part_{i:03d}' for i in range(1, 26)]\n",
    "\n",
    "for stimtype in ['io','in','s']:\n",
    "    for subject in tqdm(subjects):\n",
    "        filename = click_path / f'{subject}_{stimtype}_click_erp.pkl'\n",
    "        if filename.exists() and not rewrite_output:\n",
    "            print('skipping', subject, filename)\n",
    "            continue\n",
    "\n",
    "        if verbose: print('loading', stimtype, subject)\n",
    "\n",
    "        datadict = eel.load.unpickle(preprocessed_path / f'{subject}_{stimtype}_clicks_{ch}_reref_{refs[0]}{refs[1]}.pkl')\n",
    "\n",
    "        eegk = 'eeg'\n",
    "\n",
    "        if verbose: print('preprocessing')\n",
    "        # ergp, ergn are positive and negative rectified Erg1 signals\n",
    "        eeg, erg, ergp, ergn = pre.preprocess_eeg_clicks(datadict, verbose=verbose, eegk=eegk)\n",
    "\n",
    "        res_dict = {} # store results in a dictionary\n",
    "\n",
    "        if verbose: print('fitting ERP')\n",
    "        # filter EEG before fitting\n",
    "        if filttype == 'FIR':\n",
    "            eegfilt = eel.filter_data(eeg, lowc, highc)\n",
    "        elif filttype == 'IIRsos':\n",
    "            filtsos = scipy.signal.butter(1, [lowc, highc], btype='pass', analog=False, output='sos', fs=16384)\n",
    "            eegfilt = eeg.copy()\n",
    "            eegfilt.x = scipy.signal.sosfilt(filtsos, eegfilt.x)\n",
    "            \n",
    "        erp, triggers = md.fit_ERP(eegfilt.copy(), erg, twin[0], twin[1], verbose=verbose)\n",
    "        erp = erp.sub(time=(-0.02, 0.04))\n",
    "        res_dict['erp'] = erp\n",
    "\n",
    "        if verbose: print('saving')\n",
    "        eel.save.pickle(res_dict, click_path / f'{subject}_{stimtype}_click_erp.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19b70cda-2947-4a49-8147-6b6fdbaef09f",
   "metadata": {},
   "source": [
    "# Load predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2e3d19",
   "metadata": {},
   "source": [
    "## Load rectified wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05ff49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadict = eel.load.unpickle(preprocessed_path / f'part_001_in_speech_Cz_reref_ergs.pkl')\n",
    "ergs = [e.sub(time=(1, 245)) for e in datadict['ergs']]\n",
    "ergs = eel.combine([e-e.mean() for e in ergs])\n",
    "\n",
    "rectps = []\n",
    "rectns = []\n",
    "wavs = []\n",
    "for i in tqdm(range(8)):\n",
    "    wav = ergs[i].copy()\n",
    "    wav /= wav.abs().max()\n",
    "    wav = eel.resample(eel.NDVar(wav.x, eel.UTS(1, wav.time.tstep, len(wav))), 16384)\n",
    "    rectps.append(wav.clip(min=0))\n",
    "    rectns.append(-(wav.clip(max=0)))\n",
    "    wavs.append(wav)\n",
    "\n",
    "preds_in = {}\n",
    "preds_in['rectp'] = rectps\n",
    "preds_in['rectn'] = rectns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ef90a0",
   "metadata": {},
   "source": [
    "## Load Zilany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8e9852",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_make = False\n",
    "zilany_filename = pathlib.Path(predictor_path / f'part_001_in_speech_erg_short_wav_zilany_hsr_posneg_all.pkl')\n",
    "\n",
    "if not zilany_filename.exists() or force_make:\n",
    "    zilanyps = []\n",
    "    zilanyns = []\n",
    "    for i in tqdm(range(8)):\n",
    "        aa = eel.load.unpickle(predictor_path / f'part_001_in_speech_erg_short_wav_{i}_zilany_hsr_approx_pos0.pkl')\n",
    "        aa = eel.NDVar(aa.x, eel.UTS(1, aa.time.tstep, len(aa)))\n",
    "        zilanyps.append(aa)\n",
    "        aa = eel.load.unpickle(predictor_path / f'part_001_in_speech_erg_short_wav_{i}_zilany_hsr_approx_pos1.pkl')\n",
    "        aa = eel.NDVar(aa.x, eel.UTS(1, aa.time.tstep, len(aa)))\n",
    "        zilanyns.append(aa)\n",
    "    eel.save.pickle([zilanyps, zilanyns], zilany_filename)\n",
    "else:\n",
    "    zilanyps, zilanyns = eel.load.unpickle(zilany_filename)\n",
    "\n",
    "preds_in['zilany_hsrp'] = zilanyps\n",
    "preds_in['zilany_hsrn'] = zilanyns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479ba9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in preds_in:\n",
    "    preds_in[k] = eel.combine(preds_in[k]).sub(time=(1, 245))\n",
    "    print(k, preds_in[k].time.tmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2b23c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65f0f277",
   "metadata": {},
   "source": [
    "# Check for delays in predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48f38d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find predictor delays by cross correlating with rectified speech\n",
    "import statistics\n",
    "\n",
    "\n",
    "pred_corr_vals_mean = {}\n",
    "pred_corr_vals_std = {}\n",
    "pred_corr_lats_mean = {}\n",
    "pred_corr_lats_median = {}\n",
    "pred_corr_lats_mode = {}\n",
    "pred_corr_lats_std = {}\n",
    "pred_corr_vals_all = {}\n",
    "pred_corr_lats_all = {}\n",
    "\n",
    "ks = ['zilany_hsr']\n",
    "\n",
    "for k in ks:\n",
    "    for sign in ['p', 'n']:\n",
    "        x1 = preds_in[k+sign].copy()\n",
    "        x2 = preds_in['rect'+sign].copy()\n",
    "        corrvals1 = []\n",
    "        corrlats1 = []\n",
    "        fs1 = int(1/x1.time.tstep)\n",
    "        fs2 = int(1/x2.time.tstep)\n",
    "        print(fs1, fs2)\n",
    "        N = len(x1[0].x)\n",
    "        correlation_lags = scipy.signal.correlation_lags(N, N)\n",
    "        for i in tqdm(range(8)):\n",
    "            corrsig = scipy.signal.correlate(x1[i].x, x2[i].x)\n",
    "            corrval = np.max(corrsig)\n",
    "            corrlat = correlation_lags[np.argmax(corrsig)]\n",
    "            corrvals1.append(corrval)\n",
    "            corrlats1.append(corrlat*preds_in['rect'+sign][i].time.tstep*1000)\n",
    "        pred_corr_vals_mean[k+sign] = np.mean(corrvals1)\n",
    "        pred_corr_vals_std[k+sign] = np.std(corrvals1)\n",
    "        pred_corr_lats_mean[k+sign] = np.mean(corrlats1)\n",
    "        pred_corr_lats_mode[k+sign] = max(set(corrlats1), key=corrlats1.count)\n",
    "        pred_corr_lats_median[k+sign] = statistics.median(corrlats1)\n",
    "        pred_corr_lats_std[k+sign] = np.std(corrlats1)\n",
    "        pred_corr_vals_all[k+sign] = corrvals1\n",
    "        pred_corr_lats_all[k+sign] = corrlats1\n",
    "        print(f'{k}{sign} corr val = {pred_corr_vals_mean[k+sign]:.4f} +- {pred_corr_vals_std[k+sign]:.4f}')\n",
    "        print(f'corr lat mean = {pred_corr_lats_mean[k+sign]:.2f} +- {pred_corr_lats_std[k+sign]:.4f}, mode = {pred_corr_lats_mode[k+sign]:.2f}, median = {pred_corr_lats_median[k+sign]:.2f}')\n",
    "    print(f'{k} corr lat avg = {0.5*(pred_corr_lats_median[k+\"p\"]+pred_corr_lats_median[k+\"n\"]):.2f}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4986b7ff-a610-46fa-a9ed-ce761952f67c",
   "metadata": {},
   "source": [
    "# Speech TRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pre)\n",
    "importlib.reload(md)\n",
    "importlib.reload(plotting)\n",
    "\n",
    "fsds = 4096 # downsampling frequency\n",
    "fit_null_model = True\n",
    "verbose = True\n",
    "rewrite_output = False\n",
    "corr_lc = 30 # filter lower cutoff for prediction stage\n",
    "corr_hc = 1000 # filter upper cutoff for prediction stage\n",
    "\n",
    "speech_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ordering = eel.load.tsv('BalanceReceipe.csv') # order of presentation of stimuli\n",
    "stimnames = ['1a', '1b', '2a', '2b','3a', '3b', '4a', '4b',]\n",
    "\n",
    "shifts1 = [0, 0.0011] # shift to compensate inherent lags in ANM\n",
    "ks = ['rect', 'zilany_hsr']\n",
    "\n",
    "rNsA = {'in':[], 's':[]} # to store percentage of data rejected due to artifacts\n",
    "\n",
    "for stimtype in ['in', 's']:\n",
    "    if stimtype == 'in':\n",
    "        special_subj = ['part_024', 'part_018']\n",
    "        special_subj_idxs = [[0, 1, 3, 4, 5, 6], [0, 1, 2, 3, 4, 5, 6]]\n",
    "        shifts = [s-0.001 for s in shifts1] # insert delay 0.001\n",
    "    else:\n",
    "        special_subj = []\n",
    "        special_subj_idxs = []\n",
    "        shifts = [s-0.0043 for s in shifts1] # speaker delay 0.0043\n",
    "    tmin = preds_in[ks[0]+'p'].time.tmin\n",
    "    tmax = preds_in[ks[0]+'p'].time.tmin + 240 \n",
    "    print(tmin, tmax)\n",
    "    for subject in tqdm(subjects, f'running {stimtype}_speech'):\n",
    "        if verbose: print(subject)  \n",
    "        savefile = speech_path / f'{subject}_{stimtype}_res.pkl'\n",
    "        \n",
    "        if savefile.exists() and not rewrite_output:\n",
    "            print('skipping', subject, stimtype, filename)\n",
    "            continue\n",
    "\n",
    "        if verbose: print('loading')\n",
    "        datadict = eel.load.unpickle(preprocessed_path / f'{subject}_{stimtype}_speech_Cz_reref_ergs.pkl')\n",
    "        preds = {}\n",
    "        for ik, k in enumerate(ks):\n",
    "            preds[k] = [preds_in[k+'p'].copy(), preds_in[k+'n'].copy()]\n",
    "\n",
    "        # reorder according to presented stimulus order for this subject\n",
    "        order_subj = [stimnames.index(ordering[f'sord_ab_{i+1}'][int(subject[-2:])-1]) for i in range(8)]\n",
    "        order_subj_name = [ordering[f'sord_ab_{i+1}'][int(subject[-2:])-1] for i in range(8)]\n",
    "        print(order_subj, order_subj_name)  \n",
    "        ssi1 = range(8)\n",
    "        for ss, ssi in zip(special_subj, special_subj_idxs):\n",
    "            if subject == ss:\n",
    "                print(ss, subject, ssi)\n",
    "                for k in preds.keys():\n",
    "                    pred = preds[k]\n",
    "                    if isinstance(pred, list):\n",
    "                        preds11 = []\n",
    "                        for p in pred:\n",
    "                            preds11.append([p[i] for i in ssi])\n",
    "                        preds[k] = preds11\n",
    "                    else:\n",
    "                        preds[k] = [pred[i] for i in ssi]\n",
    "                ssi1 = ssi\n",
    "                break\n",
    "            else:\n",
    "                ssi1 = range(8)\n",
    "        order_ssi = np.argsort([order_subj.index(s) for s in ssi1])\n",
    "        print(ssi1, order_ssi)\n",
    "        if stimtype == 's' and subject == 'part_013':\n",
    "            eegnewT = eel.UTS(datadict['eegs'][4].time.tmin, datadict['eegs'][4].time.tstep, int(250/datadict['eegs'][4].time.tstep))\n",
    "            eegnew = eel.NDVar(np.zeros(len(eegnewT)), eegnewT)\n",
    "            eegnew.x[:len(datadict['eegs'][4])] = datadict['eegs'][4].x \n",
    "            datadict['eegs'][4] = eegnew\n",
    "            \n",
    "        # preprocess eeg\n",
    "        eegs, preds, rNs = pre.preprocess_eeg_speech_preds(datadict['eegs'], preds, verbose=verbose, tmin=2, tmax=242, filt_method='iir')\n",
    "        rNsA[stimtype].append(rNs)\n",
    "\n",
    "        eegs = eel.combine([eegs[i] for i in order_ssi])\n",
    "        for k in preds.keys():\n",
    "            preds[k] = [eel.combine([preds[k][0][i] for i in order_ssi]), eel.combine([preds[k][1][i] for i in order_ssi])] \n",
    "        print(order_subj_name, order_subj, ssi1, order_ssi)\n",
    "        \n",
    "        if fsds:\n",
    "            if verbose: print('downsampling')\n",
    "            eegs = eel.resample(eegs, fsds)\n",
    "            for k in preds.keys():\n",
    "                preds[k] = [eel.resample(x, fsds).clip(min=0) for x in preds[k]]\n",
    "        \n",
    "        eegs /= eegs.std()\n",
    "        for k in preds.keys():\n",
    "            preds[k] = [x/x.std() for x in preds[k]]\n",
    "\n",
    "        if verbose: print('fitting TRFs')\n",
    "\n",
    "        trfsA = {}\n",
    "        corrsA = {}\n",
    "        print(eegs, eegs.time.tmin, eegs.time.tmax)\n",
    "        permshift = 30 # shift seconds for permuted models\n",
    "\n",
    "        print(ks)\n",
    "        for t in tqdm(range(1, len(eegs))): # datalength analysis\n",
    "            for ik, k in enumerate(ks):\n",
    "                print(k)\n",
    "                trfcvs = []\n",
    "                corrcvs = []\n",
    "                trfcvsperm = []\n",
    "                corrcvsperm = []\n",
    "                cvpredp = preds[k][0][:t+1].copy()\n",
    "                cvpredn = preds[k][1][:t+1].copy()\n",
    "                cveegs = eegs[:t+1].copy()\n",
    "                for cv in range(t+1): # leave-one-out crossvalidation\n",
    "                    train_predp = eel.combine([cvpredp[cvi] for cvi in range(t+1) if cvi!=cv])\n",
    "                    train_predn = eel.combine([cvpredn[cvi] for cvi in range(t+1) if cvi!=cv])\n",
    "                    train_eeg = eel.combine([cveegs[cvi] for cvi in range(t+1) if cvi!=cv])\n",
    "\n",
    "                    test_predp = cvpredp[cv].copy()\n",
    "                    test_predn = cvpredn[cv].copy()\n",
    "                    test_eeg = eel.filter_data(cveegs[cv], corr_lc, corr_hc).copy()\n",
    "    \n",
    "                    trf1, trfp1, trfn1 = md.fit_trf_posneg(train_eeg, train_predp, train_predn, trfstr=f' {k} {t} {cv}')\n",
    "                    trf1_a = eel.NDVar(trf1.x, eel.UTS(-5+shifts[ik], trf1.time.tstep, len(trf1))).sub(time=(-4, 4))\n",
    "                    trfp1_a = eel.NDVar(trfp1.x, eel.UTS(-5+shifts[ik], trf1.time.tstep, len(trfp1))).sub(time=(-4, 4))\n",
    "                    trfn1_a = eel.NDVar(trfn1.x, eel.UTS(-5+shifts[ik], trf1.time.tstep, len(trfn1))).sub(time=(-4, 4))\n",
    "\n",
    "                    trfsA[f'trf {k} {t} {cv}'] = trf1_a.copy()\n",
    "                    trfsA[f'trf {k} {t} {cv} pos'] = trfp1_a.copy()\n",
    "                    trfsA[f'trf {k} {t} {cv} neg'] = trfn1_a.copy()\n",
    "                    trfcvs.append(trf1_a)\n",
    "\n",
    "                    trf1 = eel.filter_data(trf1, corr_lc, corr_hc).sub(time=(-0.01-shifts[ik], 0.03-shifts[ik]))\n",
    "                    ypredap = eel.filter_data(eel.convolve(trf1, test_predp), corr_lc, corr_hc)\n",
    "                    ypredan = eel.filter_data(eel.convolve(trf1, test_predn), corr_lc, corr_hc) \n",
    "                    corrsA[f'corr {k} {t} {cv}'] = np.corrcoef(test_eeg.x, ypredap.x + ypredan.x)[0,1]\n",
    "                    corrcvs.append(corrsA[f'corr {k} {t} {cv}'])\n",
    "\n",
    "                    if fit_null_model:\n",
    "                        trfperms = []\n",
    "                        corrperms = []\n",
    "                        for ip in range(1,4): # permutations\n",
    "                            train_predp_perm = train_predp.copy()\n",
    "                            train_predn_perm = train_predn.copy()\n",
    "                            fs1 = 1/train_predp.time.tstep\n",
    "                            if len(train_predp.x.shape) == 1:\n",
    "                                train_predp_perm.x[int(ip*permshift*fs1):] = train_predp.x[:-int(ip*permshift*fs1)]\n",
    "                                train_predp_perm.x[:int(ip*permshift*fs1)] = train_predp.x[-int(ip*permshift*fs1):]\n",
    "                                train_predn_perm.x[int(ip*permshift*fs1):] = train_predn.x[:-int(ip*permshift*fs1)]\n",
    "                                train_predn_perm.x[:int(ip*permshift*fs1)] = train_predn.x[-int(ip*permshift*fs1):]\n",
    "                            else:\n",
    "                                train_predp_perm.x[:,int(ip*permshift*fs1):] = train_predp.x[:,:-int(ip*permshift*fs1)]\n",
    "                                train_predp_perm.x[:,:int(ip*permshift*fs1)] = train_predp.x[:,-int(ip*permshift*fs1):]\n",
    "                                train_predn_perm.x[:,int(ip*permshift*fs1):] = train_predn.x[:,:-int(ip*permshift*fs1)]\n",
    "                                train_predn_perm.x[:,:int(ip*permshift*fs1)] = train_predn.x[:,-int(ip*permshift*fs1):]\n",
    "\n",
    "                            trf1, trfp1, trfn1 = md.fit_trf_posneg(train_eeg, train_predp_perm, train_predn_perm, trfstr=f' {k} {t} {cv} perm {ip}')\n",
    "                            trf1_a = eel.NDVar(trf1.x, eel.UTS(-5+shifts[ik], trf1.time.tstep, len(trf1))).sub(time=(-4, 4))\n",
    "                            trfp1_a = eel.NDVar(trfp1.x, eel.UTS(-5+shifts[ik], trf1.time.tstep, len(trfp1))).sub(time=(-4, 4))\n",
    "                            trfn1_a = eel.NDVar(trfn1.x, eel.UTS(-5+shifts[ik], trf1.time.tstep, len(trfn1))).sub(time=(-4, 4))\n",
    "                            trfperms.append(trf1_a)\n",
    "\n",
    "                            trf1 = eel.filter_data(trf1, corr_lc, corr_hc).sub(time=(-0.01-shifts[ik], 0.03-shifts[ik]))\n",
    "                            ypredap = eel.filter_data(eel.convolve(trf1, test_predp), corr_lc, corr_hc)\n",
    "                            ypredan = eel.filter_data(eel.convolve(trf1, test_predn), corr_lc, corr_hc)\n",
    "                            corrperms.append(np.corrcoef(test_eeg.x, ypredap.x + ypredan.x)[0,1])\n",
    "\n",
    "                        trfsA[f'trf {k} {t} {cv} null'] = eel.combine(trfperms).mean('case')\n",
    "                        corrsA[f'trf {k} {t} {cv} null'] = np.mean(corrperms)\n",
    "                        trfcvsperm.append(trfsA[f'trf {k} {t} {cv} null'])\n",
    "                        corrcvsperm.append(corrsA[f'trf {k} {t} {cv} null'])\n",
    "\n",
    "                trfsA[f'trf {k} {t}'] = eel.combine(trfcvs).mean('case')\n",
    "                corrsA[f'corr {k} {t}'] = np.mean(corrcvs)\n",
    "\n",
    "                if fit_null_model:\n",
    "                    trfsA[f'trf {k} {t} null'] = eel.combine(trfcvsperm).mean('case')\n",
    "                    corrsA[f'corr {k} {t} null'] = np.mean(corrcvsperm)\n",
    "\n",
    "            for k in ks:\n",
    "                if fit_null_model:\n",
    "                    printstr = f\"{k} {t} AVG, corr = {corrsA[f'corr {k} {t}']}, null = {corrsA[f'corr {k} {t} null']}, corr-null = {corrsA[f'corr {k} {t}'] - corrsA[f'corr {k} {t} null']}\"\n",
    "                else:\n",
    "                    printstr = f\"{k} {t} AVG, corr = {corrsA[f'corr {k} {t}']}\"\n",
    "                print(printstr)\n",
    "\n",
    "        settings = dict(order_ssi=order_ssi, order_subj_name=order_subj_name, order_subj=order_subj, shifts=shifts, tmin=tmin, tmax=tmax, fsds=fsds)\n",
    "        eel.save.pickle(dict(trfsA=trfsA, corrsA=corrsA, settings=settings, rNs=rNs, settings=settings), speech_path / f'{subject}_{stimtype}_res.pkl')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f39bce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eelcurrent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "08062936116bb98dc5346469bb79429e15c62974c13b85a49aad973e8c4ef7c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
