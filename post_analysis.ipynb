{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import eelbrain as eel\n",
    "import numpy as np\n",
    "import scipy, pathlib, importlib, mne, time, os, statsmodels, statsmodels.stats.multitest\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import preprocessing as pre\n",
    "import models as md\n",
    "import plotting\n",
    "from pathnames import *\n",
    "importlib.reload(pre)\n",
    "importlib.reload(md)\n",
    "importlib.reload(plotting)\n",
    "\n",
    "mne.set_log_level(verbose='error')\n",
    "\n",
    "# CHANGE PATH HERE\n",
    "out_path_post.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "subjects = [f'part_{i:03d}' for i in range(1, 26) if i not in [12]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function: process_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_trf(tt, trftime=(-0.01, 0.03), pktime=(0.004, 0.009), snrtime=(0, 0.015), baselinetime=(-0.01,0), sm=0.002, snrflag=True):\n",
    "    tt = eel.resample(eel.filter_data(tt, 30, 500), 16384)\n",
    "    tt -= tt.sub(time=baselinetime).mean('time')\n",
    "    tt = eel.resample(tt, 16384)\n",
    "\n",
    "    # get wave V peak\n",
    "    ttpk = tt.sub(time=pktime)\n",
    "    maxima = scipy.signal.argrelextrema(ttpk.x, np.greater)\n",
    "    if len(maxima[0])==0:\n",
    "        pkidx = np.argmax(ttpk.x)\n",
    "    else:\n",
    "        maxima_v = []\n",
    "        for m in maxima[0]:\n",
    "            maxima_v.append(ttpk.x[m])\n",
    "        pkidx = maxima[0][np.argmax(maxima_v)]\n",
    "    pktime = ttpk.time.times[pkidx]\n",
    "    pkamp = tt.sub(time=(pktime))\n",
    "\n",
    "    # calculate SNR\n",
    "    if snrflag:\n",
    "        spow = tt.sub(time=(pktime-0.0025, pktime+0.0025)).var()\n",
    "        snrwin = 0.005\n",
    "        tstarts = np.arange(-0.5, -0.02, snrwin)\n",
    "        npow = 0\n",
    "        for tstart in tstarts:\n",
    "            npow += tt.sub(time=(tstart, tstart+snrwin)).var()\n",
    "        npow /= len(tstarts)\n",
    "        snr = 10*np.log10(np.max([(spow-npow)/npow, 10**(-0.5)]))\n",
    "    else:\n",
    "        snr = None\n",
    "    return tt, pktime, pkamp, snr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load trfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_delays = {'in':-0.0009, 'io':-0.0009, 's':-0.0044} # delays for inserts and speakers\n",
    "stim_delays_trf = {'in':0.0001, 'io':0.0001, 's':-0.0001} # fix for trfs estimated with inserts -1ms and speakers -4.3ms\n",
    "\n",
    "preds = ['rect', 'rect', 'zilany_hsr', 'zilany_hsr']\n",
    "predlabels = ['RS', 'RSnull', 'AN', 'ANnull']\n",
    "\n",
    "# setup result dictionaries\n",
    "resdict = {}\n",
    "trftrialdict = {}\n",
    "corrtrialdict = {}\n",
    "snrdict = {}\n",
    "corrdict = {}\n",
    "pklatsdict = {}\n",
    "pkampsdict = {}\n",
    "for stimtype in ['io', 'in', 's']:\n",
    "    for method in ['erp']:\n",
    "        resdict[stimtype + '_click_' + method] = []\n",
    "        pklatsdict[stimtype + '_click_' + method] = []\n",
    "        pkampsdict[stimtype + '_click_' + method] = []\n",
    "\n",
    "for stimtype in ['in', 's']:\n",
    "    for pred in predlabels:\n",
    "        resdict[stimtype + '_speech_' + pred] = []\n",
    "        trftrialdict[stimtype + '_speech_'+pred] = []\n",
    "        corrtrialdict[stimtype + '_speech_'+pred] = []\n",
    "        snrdict[stimtype + '_speech_'+pred] = []\n",
    "        corrdict[stimtype + '_speech_' + pred] = []\n",
    "        pklatsdict[stimtype + '_speech_' + pred] = []\n",
    "        pkampsdict[stimtype + '_speech_' + pred] = []\n",
    "        \n",
    "# time window to detect wave V peak\n",
    "pkt1 = 0.004\n",
    "pkt2 = 0.009\n",
    "\n",
    "fs = 16384\n",
    "\n",
    "# TRF time window\n",
    "t1 = -0.01\n",
    "t2 = 0.03\n",
    "N = int((t2-t1)*fs)\n",
    "\n",
    "for subject in tqdm(subjects):\n",
    "    # Clicks\n",
    "    for stimtype in ['io', 'in', 's']:\n",
    "        click_res = eel.load.unpickle(click_path / f'{subject}_{stimtype}_click_erp.pkl')\n",
    "        trf = click_res['erp']\n",
    "        trf *= 1e6 # V -> uV\n",
    "        trf = pre.shift_NDVar(trf, stim_delays[stimtype]) # shift to account for delays\n",
    "        trf = trf.sub(time=(t1, t2))\n",
    "        trf = eel.NDVar(trf.x[:N], eel.UTS(t1, trf.time.tstep, N))\n",
    "        trf -= trf.sub(time=(t1, 0)).mean('time')\n",
    "\n",
    "        # detect wave V peak\n",
    "        ttpk = trf.sub(time=(0.004,0.009))\n",
    "        maxima = scipy.signal.argrelextrema(ttpk.x, np.greater)\n",
    "        if len(maxima[0])==0:\n",
    "            pkidx = np.argmax(ttpk.x)\n",
    "        else:\n",
    "            maxima_v = []\n",
    "            for m in maxima[0]:\n",
    "                maxima_v.append(ttpk.x[m])\n",
    "            pkidx = maxima[0][np.argmax(maxima_v)]\n",
    "        pktime = ttpk.time.times[pkidx]\n",
    "        pkamp = trf.sub(time=(pktime))\n",
    "        pklatsdict[f'{stimtype}_click_erp'].append(pktime)\n",
    "        pkampsdict[f'{stimtype}_click_erp'].append(pkamp)\n",
    "        resdict[f'{stimtype}_click_erp'].append(trf)\n",
    "\n",
    "\n",
    "    # Speech\n",
    "    for stimtype in ['in', 's']:\n",
    "        # some subjects don't have all 8 trials\n",
    "        if '024' in subject and stimtype=='in':\n",
    "            trialnum = 5\n",
    "        elif '018' in subject and stimtype=='in':\n",
    "            trialnum = 6\n",
    "        else:\n",
    "            trialnum = 7 # for 8 trials (indexed starting from 0)\n",
    "        \n",
    "\n",
    "        if stimtype == 'in':\n",
    "            res = eel.load.unpickle(speech_path_in / f'{subject}_{stimtype}_res.pkl')\n",
    "        elif stimtype == 's':\n",
    "            res = eel.load.unpickle(speech_path_s / f'{subject}_{stimtype}_res.pkl')\n",
    "        for k, kl in zip(preds, predlabels):\n",
    "            # load TRFs for each trial\n",
    "            trfs = []\n",
    "            corrs = []\n",
    "            snrs = []\n",
    "            pktimes = []\n",
    "            pkamps = []\n",
    "            for t in range(1, trialnum+1):\n",
    "                if 'null' in kl: \n",
    "                    kk = f'{k} {t} null'\n",
    "                    trf1 = res['trfsA'][f'trf {kk}'].copy()\n",
    "                else: \n",
    "                    kk = f'{k} {t}'\n",
    "                    trf1 = res['trfsA'][f'trf {kk}'].copy()\n",
    "                trf1 = pre.shift_NDVar(trf1, stim_delays_trf[stimtype]) # shift to account for delays\n",
    "                tt, pktime, pkamp, snr = process_trf(trf1)\n",
    "                tt = eel.NDVar(tt.sub(time=(t1, t2+0.1)).x[:N], eel.UTS(t1, tt.time.tstep, N))\n",
    "                trfs.append(tt)\n",
    "                pktimes.append(pktime)\n",
    "                pkamps.append(pkamp)\n",
    "                corrs.append(res['corrsA'][f'corr {kk}'])\n",
    "                snrs.append(snr)\n",
    "            trftrialdict[f'{stimtype}_speech_{kl}'].append(trfs)\n",
    "            corrtrialdict[f'{stimtype}_speech_{kl}'].append(corrs)\n",
    "            snrdict[f'{stimtype}_speech_{kl}'].append(snrs)\n",
    "                \n",
    "            pklatsdict[f'{stimtype}_speech_{kl}'].append(pktimes[-1])\n",
    "            pkampsdict[f'{stimtype}_speech_{kl}'].append(pkamps[-1])\n",
    "            resdict[f'{stimtype}_speech_{kl}'].append(trftrialdict[f'{stimtype}_speech_{kl}'][-1][-1])\n",
    "            corrdict[f'{stimtype}_speech_{kl}'].append(corrtrialdict[f'{stimtype}_speech_{kl}'][-1][-1])\n",
    "\n",
    "\n",
    "for k in resdict.keys():\n",
    "    print(k)\n",
    "    resdict[k] = eel.combine(resdict[k])\n",
    "\n",
    "\n",
    "# normalize to be comparable to ERP\n",
    "gn = {}\n",
    "for stimtype in ['in', 's']:\n",
    "    for pred in ['RS', 'AN']:\n",
    "        gn[f'{stimtype}_speech_{pred}'] = resdict[f'{stimtype}_click_erp'].sub(time=(0,0.02)).std().mean() / resdict[f'{stimtype}_speech_{pred}'].sub(time=(0,0.02)).std().mean()\n",
    "        resdict[f'{stimtype}_speech_{pred}'] *= gn[f'{stimtype}_speech_{pred}']\n",
    "        pkampsdict[f'{stimtype}_speech_{pred}'] = [p*gn[f'{stimtype}_speech_{pred}'] for p in pkampsdict[f'{stimtype}_speech_{pred}']]\n",
    "        resdict[f'{stimtype}_speech_{pred}null'] *= gn[f'{stimtype}_speech_{pred}']\n",
    "        pkampsdict[f'{stimtype}_speech_{pred}null'] = [p*gn[f'{stimtype}_speech_{pred}'] for p in pkampsdict[f'{stimtype}_speech_{pred}null']]\n",
    "\n",
    "for k in gn.keys():\n",
    "    print(k, gn[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print out wave V lats and amps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in pklatsdict.keys():\n",
    "    if 'perm' in k or 'io' in k:\n",
    "        continue\n",
    "    print(k, f'latency mean={1000*np.mean(pklatsdict[k])}, std={1000*np.std(pklatsdict[k])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predfac = []\n",
    "subfac = []\n",
    "snrfac = []\n",
    "corrfac = []\n",
    "corrfac = []\n",
    "stimfac = []\n",
    "lenfac = []\n",
    "for pred in ['AN', 'RS']:\n",
    "    for stim in ['in', 's']:\n",
    "        for length in range(7):\n",
    "            for isub, subject in enumerate(subjects):\n",
    "                if subject in ['part_018', 'part_024']:\n",
    "                    continue\n",
    "                predfac.append(pred)\n",
    "                subfac.append(subject)\n",
    "                stimfac.append(stim)\n",
    "                k = f'{stim}_speech_{pred}'\n",
    "                snrfac.append(snrdict[k][isub][length])\n",
    "                corrfac.append(corrtrialdict[k][isub][length]-corrtrialdict[k+'null'][isub][length])\n",
    "                lenfac.append(length)\n",
    "ds = eel.Dataset()\n",
    "ds['pred'] = eel.Factor(predfac)\n",
    "ds['len'] = eel.Factor(lenfac)\n",
    "ds['lenvar'] = eel.Var(lenfac)\n",
    "ds['stim'] = eel.Factor(stimfac)\n",
    "ds['corr'] = eel.Var(corrfac)\n",
    "ds['subject'] = eel.Factor(subfac, random=True)\n",
    "ds['snr'] = eel.Var(snrfac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.stats.multitest\n",
    "\n",
    "tts = []\n",
    "kks = []\n",
    "pps = []\n",
    "mn1s = []\n",
    "mn2s = []\n",
    "dds = []\n",
    "\n",
    "y1 = np.asarray(list(ds.sub(f'len==\"6\"').sub(f'stim==\"in\"').sub('pred==\"RS\"')['corr']))\n",
    "y2 = np.asarray(list(ds.sub(f'len==\"6\"').sub(f'stim==\"s\"').sub('pred==\"RS\"')['corr']))\n",
    "t, pp = scipy.stats.ttest_rel(y1, y2, alternative='two-sided')\n",
    "kk = f'RS_in_s'\n",
    "tts.append(t)\n",
    "pps.append(pp)\n",
    "kks.append(kk)\n",
    "mn1s.append(np.mean(y1))\n",
    "mn2s.append(np.mean(y2))\n",
    "dds.append(np.mean(y1-y2)/np.std(y1-y2))\n",
    "\n",
    "y1 = np.asarray(list(ds.sub(f'len==\"6\"').sub(f'stim==\"in\"').sub('pred==\"AN\"')['corr']))\n",
    "y2 = np.asarray(list(ds.sub(f'len==\"6\"').sub(f'stim==\"s\"').sub('pred==\"AN\"')['corr']))\n",
    "t, pp = scipy.stats.ttest_rel(y1, y2, alternative='two-sided')\n",
    "kk = f'AN_in_s'\n",
    "tts.append(t)\n",
    "pps.append(pp)\n",
    "kks.append(kk)\n",
    "mn1s.append(np.mean(y1))\n",
    "mn2s.append(np.mean(y2))\n",
    "dds.append(np.mean(y1-y2)/np.std(y1-y2))\n",
    "\n",
    "y1 = np.asarray(list(ds.sub(f'len==\"6\"').sub(f'stim==\"in\"').sub('pred==\"AN\"')['corr']))\n",
    "y2 = np.asarray(list(ds.sub(f'len==\"6\"').sub(f'stim==\"in\"').sub('pred==\"RS\"')['corr']))\n",
    "t, pp = scipy.stats.ttest_rel(y1, y2, alternative='two-sided')\n",
    "kk = f'in_AN_RS'\n",
    "tts.append(t)\n",
    "pps.append(pp)\n",
    "kks.append(kk)\n",
    "mn1s.append(np.mean(y1))\n",
    "mn2s.append(np.mean(y2))\n",
    "dds.append(np.mean(y1-y2)/np.std(y1-y2))\n",
    "\n",
    "y1 = np.asarray(list(ds.sub(f'len==\"6\"').sub(f'stim==\"s\"').sub('pred==\"AN\"')['corr']))\n",
    "y2 = np.asarray(list(ds.sub(f'len==\"6\"').sub(f'stim==\"s\"').sub('pred==\"RS\"')['corr']))\n",
    "t, pp = scipy.stats.ttest_rel(y1, y2, alternative='two-sided')\n",
    "kk = f's_AN_RS'\n",
    "tts.append(t)\n",
    "pps.append(pp)\n",
    "kks.append(kk)\n",
    "mn1s.append(np.mean(y1))\n",
    "mn2s.append(np.mean(y2))\n",
    "dds.append(np.mean(y1-y2)/np.std(y1-y2))\n",
    "\n",
    "[_, pcorrected, _,_] = statsmodels.stats.multitest.multipletests(pps, method='holm')\n",
    "pcorrs = pcorrected\n",
    "\n",
    "for i in range(4):\n",
    "    print(f'{kks[i]}, m1={mn1s[i]:.3f}, m2={mn2s[i]:.3f}, d={dds[i]:.3f}, t{len(y1)-1}={tts[i]:.3f}, p={pcorrected[i]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kks = []\n",
    "pps = []\n",
    "tts = []\n",
    "md1s = []\n",
    "md2s = []\n",
    "for i in range(1, 7):\n",
    "    y1 = ds.sub(f'len==\"1\"').sub(f'stim==\"in\"').sub('pred==\"AN\"')['snr']\n",
    "    y2 = ds.sub(f'len==\"{i}\"').sub(f'stim==\"s\"').sub('pred==\"AN\"')['snr']\n",
    "    T, pp = scipy.stats.wilcoxon(y1, y2, alternative='two-sided')\n",
    "    kk = f'12in-{4*i+8}s'\n",
    "    tts.append(T)\n",
    "    pps.append(pp)\n",
    "    kks.append(kk)\n",
    "    md1s.append(np.median(y1))\n",
    "    md2s.append(np.median(y2))\n",
    "\n",
    "[_, pcorrected, _,_] = statsmodels.stats.multitest.multipletests(pps, method='holm')\n",
    "for kk, pp, ppc, tt, md1, md2 in zip(kks, pps, pcorrected, tts, md1s, md2s):\n",
    "    print('snr', kk, f'median1={md1:.2f}dB, median2={md2:.2f}dB, T={tt:.2f}, p_corrected={ppc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kks = []\n",
    "pps = []\n",
    "tts = []\n",
    "md1s = []\n",
    "md2s = []\n",
    "for stim in ['in', 's']:\n",
    "    y1 = ds.sub(f'len==\"6\"').sub(f'stim==\"{stim}\"').sub('pred==\"RS\"')['snr']\n",
    "    y2 = ds.sub(f'len==\"6\"').sub(f'stim==\"{stim}\"').sub('pred==\"AN\"')['snr']\n",
    "    T, pp = scipy.stats.wilcoxon(y1, y2, alternative='two-sided')\n",
    "    kk = f'{stim} RSvsAN'\n",
    "    tts.append(T)\n",
    "    pps.append(pp)\n",
    "    kks.append(kk)\n",
    "    md1s.append(np.median(y1))\n",
    "    md2s.append(np.median(y2))\n",
    "\n",
    "[_, pcorrected, _,_] = statsmodels.stats.multitest.multipletests(pps, method='holm')\n",
    "for kk, pp, ppc, tt, md1, md2 in zip(kks, pps, pcorrected, tts, md1s, md2s):\n",
    "    print('snr', kk, f'median1={md1:.2f}dB, median2={md2:.2f}dB, T={tt:.2f}, p_corrected={ppc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot fig 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plotting)\n",
    "savepath = out_path_post / 'figs_rev1_06'\n",
    "savepath.mkdir(exist_ok=True, parents=True)\n",
    "sigbars = [[0, 1, pcorrs[0]],[2, 3, pcorrs[1]],[1, 3, pcorrs[3]], [0, 2, pcorrs[2]],]\n",
    "plotting.plot_fig_AVG3(resdict, corrdict, savepath, sigbars=sigbars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % change in wave V amplitude for inserts vs soundfield\n",
    "print('click', 100*(np.mean(pkampsdict['in_click_erp'])-np.mean(pkampsdict['s_click_erp']))/np.mean(pkampsdict['in_click_erp']))\n",
    "print('RS', 100*(np.mean(pkampsdict['in_speech_RS'])-np.mean(pkampsdict['s_speech_RS']))/np.mean(pkampsdict['in_speech_RS']))\n",
    "print('AN', 100*(np.mean(pkampsdict['in_speech_AN'])-np.mean(pkampsdict['s_speech_AN']))/np.mean(pkampsdict['in_speech_AN']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot fig 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plotting)\n",
    "xks = ['in_click_erp', 'in_speech_RS', 'in_speech_AN', 'in_click_erp', 's_click_erp']\n",
    "yks = ['s_click_erp', 's_speech_RS', 's_speech_AN', 'in_speech_AN', 's_speech_AN']\n",
    "titles = ['Click ERPs', 'Speech TRFs: RS Predictor', 'Speech TRFs: ANM Predictor', 'Clicks vs. Speech: Inserts', 'Clicks vs. Speech: Sound-field']\n",
    "xstrs = ['Inserts', 'Inserts', 'Inserts', 'Click ERP', 'Click ERP']\n",
    "ystrs = ['Sound-field', 'Sound-field', 'Sound-field', 'Speech TRF ANM', 'Speech TRF ANM']\n",
    "plotting.plot_indiv_correlations(pklatsdict, pkampsdict, xks, yks, xstrs, ystrs, titles)\n",
    "plt.savefig(savepath / 'indiv_correlations_row_5_2.png', bbox_inches='tight', dpi=300)\n",
    "plt.savefig(savepath / 'indiv_correlations_row_5_2.pdf', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot fig 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "#colors = [(0,0,1,0.5), (0,0.5,0.8,0.5), (1,0,0,0.5), (0.8,0.5,0,0.5), (0,1,0,0.5), (0.5,0.8,0,0.5)]\n",
    "colors = [(0.5, 0.5, 1, 0.3), (1, 0.5, 0.5, 0.3), (0.4, 0.4, 1), (1, 0.4, 0.4)]    \n",
    "\n",
    "plt.figure(figsize=(18,15))\n",
    "\n",
    "patches = []\n",
    "plt.subplot(3,1,1)\n",
    "for ii, (k, color, label) in enumerate(zip(['in_speech_RS', 's_speech_RS', 'in_speech_AN', 's_speech_AN'], colors, \n",
    "                                                ['RS Inserts', 'RS Sound-field', 'ANM Inserts', 'ANM Sound-field'])):\n",
    "    print(k)\n",
    "    bplot = plt.boxplot([[corrtrialdict[k][isubj][ilev]-corrdict[k+'null'][isubj] for isubj in range(len(corrtrialdict[k])) if len(corrtrialdict[k][isubj])>ilev] for ilev in range(7)], \n",
    "                        positions=[i*8+ii for i in range(7)], patch_artist=True)\n",
    "    \n",
    "    for patch in bplot['boxes']:\n",
    "        patch.set_facecolor(color)\n",
    "    for m in bplot['medians']:\n",
    "        m.set_color('black')\n",
    "    patches.append(mpatches.Patch(color=color, label=label))\n",
    "plt.title('Data length vs. Model Fit', fontsize=17)\n",
    "plt.legend(handles=patches, fontsize=15)\n",
    "plt.xlabel('Data Length (mins)', fontsize=15)\n",
    "plt.xlim([-0.5, 6*8+6])\n",
    "plt.xticks([i*8+1.5 for i in range(7)])\n",
    "plt.gca().set_xticklabels([4*(i+2) for i in range(7)], fontsize=15)\n",
    "plt.yticks([-0.01, 0, 0.01, 0.02, 0.03, 0.04])\n",
    "plt.gca().set_yticklabels([-0.01, 0, 0.01, 0.02, 0.03, 0.04], fontsize=15)\n",
    "plt.ylim([-0.01, 0.055])\n",
    "for yy in [0.01, 0.02, 0.03, 0.04]:\n",
    "    plt.axhline(yy, color='k', alpha=0.2, linestyle='dashed')\n",
    "plt.axhline(0, color='k', linestyle='dashed')\n",
    "plt.ylabel('Prediction Correlation', fontsize=15)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "plt.subplot(3,1,2)\n",
    "patches = []\n",
    "for ii, (k, color, label) in enumerate(zip(['in_speech_RS', 's_speech_RS', 'in_speech_AN', 's_speech_AN'], colors, \n",
    "                                                ['RS IE', 'RS SF', 'ANM IE', 'ANM SF'])):\n",
    "    print(k)\n",
    "    bplot = plt.boxplot([[snrdict[k][isubj][ilev] for isubj in range(len(snrdict[k])) if len(snrdict[k][isubj])>ilev] for ilev in range(7)], \n",
    "                        positions=[i*8+ii for i in range(7)], patch_artist=True)\n",
    "    \n",
    "    for patch in bplot['boxes']:\n",
    "        patch.set_facecolor(color)\n",
    "    for m in bplot['medians']:\n",
    "        m.set_color('black')\n",
    "    patches.append(mpatches.Patch(color=color, label=label))\n",
    "plt.xlim([-0.5, 6*8+6])\n",
    "plt.ylim([-10, 30])\n",
    "plt.xticks([i*8+1.5 for i in range(7)])\n",
    "plt.gca().set_xticklabels([4*(i+2) for i in range(7)], fontsize=15)\n",
    "plt.yticks([0, 5, 10, 15, 20, 25])\n",
    "plt.gca().set_yticklabels([0, 5, 10, 15, 20, 25], fontsize=15)\n",
    "plt.title('Data length vs. Wave V SNR', fontsize=17)\n",
    "for yy in [5, 10, 15, 20, 25]:\n",
    "    plt.axhline(yy, color='k', alpha=0.2, linestyle='dashed')\n",
    "plt.axhline(0, color='k', linestyle='dashed')\n",
    "plt.ylabel('SNR (dB)', fontsize=15)\n",
    "plt.xlabel('Data Length (mins)', fontsize=15)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "plt.subplot(3,2,5)\n",
    "tdim = trftrialdict['s_speech_AN'][0][0].time.times*1000\n",
    "tnorm = trftrialdict['s_speech_AN'][0][-1].sub(time=(-0.01,0)).std()*1.2\n",
    "for i in range(4):\n",
    "    tt = trftrialdict['s_speech_AN'][0][4-i-1]\n",
    "    plt.plot(tdim, tt.x/tnorm + 20*i, color=(1, 0.4, 0.4), lw=2)\n",
    "    plt.text(-3, 20*i+5, f'SNR = {snrdict[\"s_speech_AN\"][0][4-i-1]:.1f} dB', fontsize=15)\n",
    "tt = trftrialdict['s_speech_AN'][0][-1]\n",
    "plt.plot(tdim, tt.x/tnorm-30, color=(1, 0.4, 0.4), lw=2)\n",
    "plt.text(-3, -30+5, f'SNR = {snrdict[\"s_speech_AN\"][0][-1]:.1f} dB', fontsize=15)\n",
    "plt.yticks([-30]+[i*20 for i in range(4)])\n",
    "plt.ylim([-47, 20*4+10])\n",
    "plt.gca().set_yticklabels([32, 20, 16, 12, 8], fontsize=15)\n",
    "plt.gca().set_xticklabels([i for i in np.arange(-5, 21, 5)], fontsize=15)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.ylabel('Data length [mins]', fontsize=15)\n",
    "plt.xlim([-5, 20])\n",
    "plt.gca().set_xticklabels([i for i in np.arange(-5, 21, 5)], fontsize=15)\n",
    "plt.xlabel('Time [ms]', fontsize=15)\n",
    "rect = mpatches.Rectangle((-5.5, -15), 1, 5, linewidth=1, edgecolor='none', zorder=3, facecolor=(1,1,1), clip_on=False)\n",
    "plt.gca().add_patch(rect)\n",
    "rect = mpatches.Rectangle((-5.5, -10), 1, 0.1, linewidth=1, edgecolor='k', zorder=3, facecolor='none', clip_on=False)\n",
    "plt.gca().add_patch(rect)\n",
    "rect = mpatches.Rectangle((-5.5, -15), 1, 0.1, linewidth=1, edgecolor='k', zorder=3, facecolor='none', clip_on=False)\n",
    "plt.gca().add_patch(rect)\n",
    "\n",
    "plt.subplot(3,2,6)\n",
    "tnorm = trftrialdict['s_speech_AN'][16][-1].sub(time=(-0.01,0)).std()*1.5\n",
    "for i in range(4):\n",
    "    tt = trftrialdict['s_speech_AN'][16][4-i-1]\n",
    "    plt.plot(tdim, tt.x/tnorm + 20*i, color=(1, 0.4, 0.4), lw=2)\n",
    "    plt.text(-3, 20*i+5, f'SNR = {snrdict[\"s_speech_AN\"][16][4-i-1]:.1f} dB', fontsize=15)\n",
    "tt = trftrialdict['s_speech_AN'][16][-1]\n",
    "plt.plot(tdim, tt.x/tnorm-30, color=(1, 0.4, 0.4), lw=2)\n",
    "plt.text(-3, -30+5, f'SNR = {snrdict[\"s_speech_AN\"][16][-1]:.1f} dB', fontsize=15)\n",
    "plt.yticks([-30]+[i*20 for i in range(4)])\n",
    "plt.ylim([-47, 20*4+10])\n",
    "plt.gca().set_yticklabels([32, 20, 16, 12, 8], fontsize=15)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.ylabel('Data length [mins]', fontsize=15)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.xlim([-5, 20])\n",
    "plt.gca().set_xticklabels([i for i in np.arange(-5, 21, 5)], fontsize=15)\n",
    "plt.xlabel('Time [ms]', fontsize=15)\n",
    "\n",
    "plt.figtext(0.4, 0.32, 'Individual sound-field ANM TRFs', fontsize=17)\n",
    "plt.figtext(0.6, 0.05,'Participant with lowest Wave V SNR (P17)', fontsize=17)\n",
    "plt.figtext(0.15, 0.05,'Participant with highest Wave V SNR (P01)', fontsize=17)\n",
    "\n",
    "rect = mpatches.Rectangle((-5.5, -15), 1, 5, linewidth=1, edgecolor='none', zorder=3, facecolor=(1,1,1), clip_on=False)\n",
    "plt.gca().add_patch(rect)\n",
    "rect = mpatches.Rectangle((-5.5, -10), 1, 0.1, linewidth=1, edgecolor='k', zorder=3, facecolor='none', clip_on=False)\n",
    "plt.gca().add_patch(rect)\n",
    "rect = mpatches.Rectangle((-5.5, -15), 1, 0.1, linewidth=1, edgecolor='k', zorder=3, facecolor='none', clip_on=False)\n",
    "plt.gca().add_patch(rect)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "out_path1 = savepath\n",
    "plt.savefig(out_path1 / 'datalength.png', bbox_inches='tight', dpi=300)\n",
    "plt.savefig(out_path1 / 'datalength.pdf', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plotting)\n",
    "savepath.mkdir(exist_ok=True)\n",
    "print(savepath)\n",
    "plotting.plot_fig_indivTRFs(resdict, pklatsdict, pkampsdict, savepath, saveflag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eelcurrent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08062936116bb98dc5346469bb79429e15c62974c13b85a49aad973e8c4ef7c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
