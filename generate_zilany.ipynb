{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eelbrain as eel\n",
    "import numpy as np\n",
    "import cochlea, tqdm, pathlib, time\n",
    "from pathnames import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load erg and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadict = eel.load.unpickle(preprocessed_path / f'part_001_in_speech_Cz_reref_ergs.pkl')\n",
    "ergs = [e.sub(time=(1, 245)) for e in datadict['ergs']]\n",
    "ergs = eel.combine([e-e.mean() for e in ergs])\n",
    "\n",
    "for i in tqdm(range(8)):\n",
    "    wav = ergs[i].copy()\n",
    "    wav /= wav.abs().max()\n",
    "    eel.save.wav(wav, predictor_folder / f'part_001_in_speech_erg_short_wav_{i}.wav')\n",
    "    eel.save.pickle(wav, predictor_folder / f'part_001_in_speech_erg_short_wav_{i}.pkl')\n",
    "    wav = eel.resample(eel.NDVar(wav.x, eel.UTS(1, wav.time.tstep, len(wav))), 16384)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate zilany (only hsr fibres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_cochlea = 100000\n",
    "cfs = 2 ** np.arange(np.log2(125), np.log2(16e3 + 1), 1./6)\n",
    "\n",
    "print('running')\n",
    "tts = []\n",
    "ANps = []\n",
    "ANns = []\n",
    "for i in tqdm.tqdm(range(8)):\n",
    "    wav = eel.load.unpickle(predictor_folder / f'part_001_in_speech_erg_wav_{i}.pkl')\n",
    "    wav1 = eel.resample(wav, fs_cochlea)\n",
    "    wav1.x = 0.0796214341107 * wav1.x / wav1.rms() # 72 dB SPL -> Pascal\n",
    "    for ip, ee in enumerate([wav1.x, -wav1.x]):\n",
    "        rr = []\n",
    "        ts = time.time()\n",
    "        for cf in tqdm.tqdm(cfs):\n",
    "            rr1 = cochlea.run_zilany2014_rate(ee,\n",
    "                                        fs_cochlea,\n",
    "                                        anf_types=['hsr'],\n",
    "                                        cf=cf,\n",
    "                                        powerlaw='approximate',\n",
    "                                        species='human')\n",
    "            rr.append(rr1)\n",
    "        rr = np.mean(np.squeeze(np.asarray(rr)), axis=0)\n",
    "        tts.append(time.time()-ts)\n",
    "        rr = eel.NDVar(rr, eel.UTS(wav.time.tstart, 1/fs_cochlea, len(rr)))\n",
    "        rr = eel.resample(rr, 1/wav.time.tstep)\n",
    "        print(rr, rr.time.tmax, f'elapsed {tts[-1]}\\n')\n",
    "        eel.save.pickle(rr, predictor_folder / f'part_001_in_speech_erg_short_wav_{i}_zilany_hsr_approx_pos{ip}.pkl')\n",
    "        if ip: ANns.append(rr) \n",
    "        else: ANps.append(rr)\n",
    "\n",
    "eel.save.pickle([ANps, ANns], predictor_folder / f'part_001_in_speech_erg_short_wav_zilany_hsr_posneg_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eelcurrent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08062936116bb98dc5346469bb79429e15c62974c13b85a49aad973e8c4ef7c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
